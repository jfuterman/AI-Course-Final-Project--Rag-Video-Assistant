{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMD/l94Ln1dHlAVbqPNKMt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ai final project/\n","\n","!pip install gradio qdrant-client sentence-transformers --quiet\n","\n","import gradio as gr\n","from qdrant_client import QdrantClient\n","from sentence_transformers import SentenceTransformer\n","import requests\n","import json\n","\n","# Load embedding model\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Connect to Qdrant cloud instance\n","qdrant_client = QdrantClient(\n","    url=\"https://0d960223-8541-4d94-abc9-ddb490e68e6d.us-east4-0.gcp.cloud.qdrant.io:6333\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.uDVtAawgI5_xJ6xuHl7L4HqICEDrLxjgFJy7ZCnHbC4\",\n",")\n","collection_name = \"video_chunks\"\n","\n","# Retrieve top relevant chunks from Qdrant\n","def retrieve_chunks(query, top_k=5):\n","    embedding = model.encode(query).tolist()\n","    results = qdrant_client.search(\n","        collection_name=collection_name,\n","        query_vector=embedding,\n","        limit=top_k\n","    )\n","    return results\n","\n","# Format prompt to send to Ollama\n","def format_prompt(query, chunks):\n","    context = \"\"\n","    for idx, hit in enumerate(chunks):\n","        context += f\"Chunk {idx+1} (Video ID: {hit.payload['video_id']}, Start: {hit.payload['start_time_ms']/1000:.2f}s)\\n\"\n","        context += f\"{hit.payload['combined_text']}\\n\\n\"\n","\n","    prompt = f\"\"\"\n","You are an educational assistant that provides answers based only on the provided video lecture content.\n","\n","Student Question:\n","{query}\n","\n","Relevant Video Chunks:\n","{context}\n","\n","Your Answer:\n","\"\"\"\n","    return prompt\n","\n","# Call Ollama (running locally)\n","def generate_streaming_response(prompt):\n","    response = requests.post(\n","        \"http://localhost:11434/api/generate\",\n","        json={\n","            \"model\": \"mistral\",\n","            \"prompt\": prompt,\n","            \"stream\": True\n","        },\n","        stream=True\n","    )\n","    for line in response.iter_lines():\n","        if line:\n","            data = json.loads(line)\n","            yield data.get(\"response\", \"\")\n","\n","# Gradio UI function\n","def gradio_chatbot(message, history):\n","    chunks = retrieve_chunks(message)\n","    prompt = format_prompt(message, chunks)\n","    response_gen = generate_streaming_response(prompt)\n","\n","    output = \"\"\n","    for chunk in response_gen:\n","        output += chunk\n","        yield output\n","\n","# Launch Gradio app\n","gr.ChatInterface(\n","    fn=gradio_chatbot,\n","    title=\" AI 1 Course RAG Video Assistant (Ollama + Qdrant)\",\n","    theme=\"soft\",\n","    chatbot=gr.Chatbot(height=400),\n","    textbox=gr.Textbox(placeholder=\"Ask about CNNs, ResNets, or cross-entropy...\", container=True)\n",").launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":715},"id":"6OZLOlZOWs4V","executionInfo":{"status":"ok","timestamp":1745978642278,"user_tz":240,"elapsed":6704,"user":{"displayName":"Jesse Futerman","userId":"11631674659738281003"}},"outputId":"6f05c1ed-d402-4a92-dd4c-fbe6ea45580f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/ai final project\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-e3cf39d9af67>:81: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n","  chatbot=gr.Chatbot(height=400),\n","/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:321: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://d7ff0c5227c94b4ce0.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://d7ff0c5227c94b4ce0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]}]}