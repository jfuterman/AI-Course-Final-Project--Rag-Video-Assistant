{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzmvG6ciME5DNMR6Z+utwM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bt0RxlQ8TM1C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745898662893,"user_tz":240,"elapsed":5988,"user":{"displayName":"Jesse Futerman","userId":"11631674659738281003"}},"outputId":"9a914b09-c53d-4c59-d5d5-ba83f8f85819"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/ai final project\n","âœ… Connected to Qdrant!\n","âœ… Model loaded\n","âœ… Retrieved 5 relevant chunks\n","\n","Formatted Prompt Preview:\n","\n","\n","You are an educational assistant that provides answers based only on the provided video lecture content.\n","\n","Student Question:\n","Explain how ResNets work\n","\n","Relevant Video Chunks:\n","Chunk 1 (Video ID: M-bIqxvF984, Start: 955.03s)\n","of the output of this kind of network of\n","\n","Chunk 2 (Video ID: JW22NeQXk64, Start: 1090.43s)\n","output of the of the network so we'll\n","\n","Chunk 3 (Video ID: M-bIqxvF984, Start: 1049.35s)\n","within the network itself within the network itself so uh the network is effectively so uh the network is effectively\n","\n","Chunk 4 (Video ID: M-bIqxvF984, Start: 1494.03s)\n","fully connected Network so we need to\n","\n","Chunk 5 (Video ID: JW22NeQXk64, Start: 5.75s)\n","we should imagine these uh networks that we should imagine these uh networks that we call fully connected Network we call fully connected Network\n","\n","\n","\n","Your Answer:\n","\n","\n","ðŸ”µ [Simulated LLM Call] ðŸ”µ\n","\n","\n","Generated Answer:\n","\n","This is a placeholder response. (Later: Replace with real LLM call to generate based on the prompt.)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-707d7da94b14>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  search_results = qdrant_client.search(\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/ai final project/\n","\n","!pip install qdrant-client sentence-transformers --quiet\n","\n","import json\n","import numpy as np\n","from tqdm import tqdm\n","from qdrant_client import QdrantClient\n","from sentence_transformers import SentenceTransformer\n","\n","# Connect to Qdrant Cloud\n","qdrant_client = QdrantClient(\n","    url=\"https://0d960223-8541-4d94-abc9-ddb490e68e6d.us-east4-0.gcp.cloud.qdrant.io:6333\",\n","    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.uDVtAawgI5_xJ6xuHl7L4HqICEDrLxjgFJy7ZCnHbC4\",\n",")\n","\n","print(\"Connected to Qdrant!\")\n","\n","# Load Embedding Model\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","print(\"Model loaded\")\n","\n","# Define Collection Name\n","collection_name = \"video_chunks\"\n","\n","# Retrieve Chunks Given a Query\n","def retrieve_chunks(query, top_k=5):\n","    \"\"\"Embed the query and retrieve top-k relevant chunks.\"\"\"\n","    query_embedding = model.encode(query).tolist()\n","\n","    search_results = qdrant_client.search(\n","        collection_name=collection_name,\n","        query_vector=query_embedding,\n","        limit=top_k\n","    )\n","\n","    return search_results\n","\n","\n","# Format Retrieved Chunks into a Prompt\n","def format_prompt(query, retrieved_chunks):\n","    \"\"\"Format the retrieved subtitles into a context prompt.\"\"\"\n","    context = \"\"\n","\n","    for idx, hit in enumerate(retrieved_chunks):\n","        context += f\"Chunk {idx+1} (Video ID: {hit.payload['video_id']}, Start: {hit.payload['start_time_ms']/1000:.2f}s)\\n\"\n","        context += f\"{hit.payload['combined_text']}\\n\\n\"\n","\n","    full_prompt = f\"\"\"\n","You are an educational assistant that provides answers based only on the provided video lecture content.\n","\n","Student Question:\n","{query}\n","\n","Relevant Video Chunks:\n","{context}\n","\n","Your Answer:\n","\"\"\"\n","\n","    return full_prompt\n","\n","# (Placeholder) Generate Answer from LLM\n","def generate_answer(prompt):\n","    print(\"\\n [Simulated LLM Call] \\n\")\n","    return \"This is a placeholder response. (Later: Replace with real LLM call to generate based on the prompt.)\"\n","\n","# Full Pipeline Test\n","query = \"Explain how ResNets work\"\n","\n","# Step 1: Retrieve\n","retrieved = retrieve_chunks(query)\n","print(f\"Retrieved {len(retrieved)} relevant chunks\")\n","\n","# Step 2: Format Prompt\n","prompt = format_prompt(query, retrieved)\n","print(\"\\nFormatted Prompt Preview:\\n\")\n","print(prompt[:1000])  # Preview first 1000 chars of prompt\n","\n","# Step 3: Generate Answer\n","response = generate_answer(prompt)\n","print(\"\\nGenerated Answer:\\n\")\n","print(response)\n"]}]}